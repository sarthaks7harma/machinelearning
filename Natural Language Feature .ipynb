{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assembly', 'session', 'brought', 'much', 'good']\n"
     ]
    }
   ],
   "source": [
    "data = brown.sents(categories='editorial')[:100]\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'General', 'Assembly', ',', 'which', 'adjourns', 'today', ',', 'has', 'performed', 'in', 'an', 'atmosphere', 'of', 'crisis', 'and', 'struggle', 'from', 'the', 'day', 'it', 'convened', '.']\n"
     ]
    }
   ],
   "source": [
    "text = data[1]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was a very pleasent day, the weather was pretty cool were some light showers.\n"
     ]
    }
   ],
   "source": [
    "text = \"it was a very pleasent day, the weather was pretty cool were some light showers.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=sent_tokenize(text)\n",
    "wordslist=word_tokenize(sentence[0].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itself', 'so', 'o', 'but', 'who', 'will', 'he', 'out', 'd', 'aren', \"mightn't\", 'weren', \"it's\", 'hers', 'most', \"mustn't\", \"you're\", \"shouldn't\", 'our', 'had', 'only', 'while', 'can', 'on', 'this', 'under', 'don', 'with', 'if', 'his', 'needn', 'during', 'did', 'we', \"should've\", 're', 'an', 'between', 'here', \"you'll\", 'same', \"haven't\", 'mightn', \"wasn't\", 'are', 'm', 'ours', 'few', 'more', 't', 'there', 'wasn', \"wouldn't\", 'when', 'the', 'further', \"aren't\", 'these', 'all', 'such', 'has', 'shan', 'just', 'wouldn', \"couldn't\", 'theirs', \"shan't\", 'above', 'until', 'any', 'each', 'y', 'you', 'where', 'nor', 'too', 'didn', 'me', 'in', 'whom', 'am', 'have', 'themselves', 'were', 'hasn', 'doesn', 'own', 'my', 'than', 'herself', 'its', 'for', 'not', \"weren't\", 'over', 'ourselves', \"won't\", 'does', \"didn't\", 'shouldn', 'myself', 'do', \"she's\", 'some', 'was', 'i', 'up', 'him', 'which', 'against', \"doesn't\", 'about', \"that'll\", 'how', 'as', 'or', 'they', 'and', 'once', 'll', 've', 'couldn', 'yours', \"needn't\", 'those', 'that', 'having', 'now', 'through', 'very', 's', \"isn't\", 'hadn', 'again', 'to', 'from', 'ain', 'both', 'she', 'them', 'isn', 'should', 'won', \"hadn't\", \"don't\", 'into', \"you'd\", 'of', 'after', 'been', 'himself', 'because', 'why', 'before', 'haven', 'her', 'yourself', 'what', 'be', 'yourselves', 'is', 'off', 'your', 'it', 'doing', 'their', 'a', 'then', \"you've\", 'mustn', 'down', 'being', 'other', \"hasn't\", 'ma', 'at', 'by', 'no', 'below'}\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "print(sw)\n",
    "print(len(sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pleasent', 'day', ',', 'weather', 'pretty', 'cool', 'light', 'showers', '.']\n"
     ]
    }
   ],
   "source": [
    "usefulwords = [w for w in wordslist if w not in sw]\n",
    "print(usefulwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send', 'all', 'the', '50', 'documents', 'related', 'to', 'clause', '1,2,3', 'at', 'abc', '@', 'gmail.com']\n",
      "['send', '50', 'documents', 'related', 'clause', '1,2,3', 'abc', '@', 'gmail.com']\n"
     ]
    }
   ],
   "source": [
    "text = \"send all the 50 documents related to clause 1,2,3 at abc@gmail.com\"\n",
    "tokenized=sent_tokenize(text)\n",
    "wordlist = word_tokenize(tokenized[0])\n",
    "print(wordlist)\n",
    "usefulwords = [w for w in wordlist if w not in sw]\n",
    "print(usefulwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['send', 'all', 'the', 'documents', 'related', 'to', 'clause', 'at', 'abc', 'gmail', 'com']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"[a-zA]+\")\n",
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
